{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ee4144b1-327d-4f43-866d-e047527e65d5",
      "metadata": {
        "id": "ee4144b1-327d-4f43-866d-e047527e65d5"
      },
      "source": [
        "LETS GET GERF AND YOLO WORKING!!!!\n",
        "\n",
        "First we're going to download ultralytics repository which contains the yolo repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "11c31dee-82e6-4648-af45-8a1aa936abf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11c31dee-82e6-4648-af45-8a1aa936abf5",
        "outputId": "b779aeea-5a5f-446f-a181-6792f4882bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 76864, done.\u001b[K\n",
            "remote: Counting objects: 100% (574/574), done.\u001b[K\n",
            "remote: Compressing objects: 100% (193/193), done.\u001b[K\n",
            "remote: Total 76864 (delta 511), reused 381 (delta 381), pack-reused 76290 (from 4)\u001b[K\n",
            "Receiving objects: 100% (76864/76864), 41.11 MiB | 16.52 MiB/s, done.\n",
            "Resolving deltas: 100% (57744/57744), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/ultralytics.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76b86751-0826-406d-bfd0-dbd2b2e6554a",
      "metadata": {
        "id": "76b86751-0826-406d-bfd0-dbd2b2e6554a"
      },
      "source": [
        "Next, we're going to copy over the custom files to the ultralytics repository\n",
        "Note, the yolo11_custom.yaml file contains the architecture that incorporates GERF model. We'll leave it inside the custom directory on purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fafeed6a-61be-4f15-8bea-5f1cbc38519c",
      "metadata": {
        "id": "fafeed6a-61be-4f15-8bea-5f1cbc38519c"
      },
      "outputs": [],
      "source": [
        "!cp custom/__init__.py ultralytics/ultralytics/nn/modules\n",
        "!cp custom/gerf_bra.py ultralytics/ultralytics/nn/modules\n",
        "!cp custom/tasks.py ultralytics/ultralytics/nn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9857d4d0-cb51-448a-b1d5-3bd40243a784",
      "metadata": {
        "id": "9857d4d0-cb51-448a-b1d5-3bd40243a784"
      },
      "source": [
        "Now, we need to export the python path to include this repository to use with our python code.\n",
        "Ideally, we would install with \"pip install -e .\" and the ultralytics toml file but for some reason,\n",
        "it would do a clean install and ignore my changes\n",
        "1. First we'll collect your current path\n",
        "2. Then we'll check what's on PYTHONPATH\n",
        "3. Add the outputs of your current path from 1 and the PYTHONPATH to the environment variable\n",
        "4. Finally, we'll verify the variable was set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "93d30cdf-4120-4c12-980c-2771a0211f1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93d30cdf-4120-4c12-980c-2771a0211f1d",
        "outputId": "7f195ac6-8a34-4375-a72a-2a33a4165066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check where the ultralytics repo is stored\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!echo \"Check where the ultralytics repo is stored\"\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3d9caaae-3f4d-4925-be5b-03707d061d15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d9caaae-3f4d-4925-be5b-03707d061d15",
        "outputId": "0a19681e-867b-4a21-f07c-2eca7dc2b68b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check current python path. Should be empty at every new session\n",
            "/env/python\n"
          ]
        }
      ],
      "source": [
        "!echo \"Check current python path. Should be empty at every new session\"\n",
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a75f0b61-f361-4528-8ff2-a99c4910e1ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a75f0b61-f361-4528-8ff2-a99c4910e1ae",
        "outputId": "a977a42f-ee93-4cd1-e46c-3995e455295f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now let's set the path. I got the below path from the pwd command and added in ultralytics\n",
            "env: PYTHONPATH=/content/ultralytics:/env/python\n"
          ]
        }
      ],
      "source": [
        "!echo \"Now let's set the path. I got the below path from the pwd command and added in ultralytics\"\n",
        "%env PYTHONPATH=/content/ultralytics:/env/python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a4d5890a-41f9-44b4-8fd8-2f80f7a17552",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4d5890a-41f9-44b4-8fd8-2f80f7a17552",
        "outputId": "76b84075-6c5a-43d5-faf1-e6a404e4cf38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check current python path. Should be updated now\n",
            "/content/ultralytics:/env/python\n"
          ]
        }
      ],
      "source": [
        "!echo \"Check current python path. Should be updated now\"\n",
        "!echo $PYTHONPATH"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "984faec7-ae60-4aa7-be10-5963cf857f1c",
      "metadata": {
        "id": "984faec7-ae60-4aa7-be10-5963cf857f1c"
      },
      "source": [
        "Now we can test out if the GERF additions are ready to use\n",
        "The first cell tests the CLI\n",
        "The second cell actually imports the custom yolo repository for python notebook usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fd3bbe46-7c9b-486c-bc5b-5930759fb97b",
      "metadata": {
        "id": "fd3bbe46-7c9b-486c-bc5b-5930759fb97b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f83d8ac-68cb-4b38-f85e-f5f8ea1f13c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "All good!\n"
          ]
        }
      ],
      "source": [
        "!python -c \"from ultralytics import YOLO; from ultralytics.nn.modules import GERF_BRA_Simple; print('All good!')\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "223b4811-ea73-425b-b83f-2ac4458b0738",
      "metadata": {
        "id": "223b4811-ea73-425b-b83f-2ac4458b0738"
      },
      "source": [
        "Now that we confirmed the module is ready, let's go ahead and create our yolo11 gerf model.\n",
        "The model is defined in custom/yolo11_custom.yaml file. One big thing to note, the argument for\n",
        "the gerf block is indicated by the \\[-1, 1, GERF_BRA, \\[512\\]\\] line. There's two GERF_BRA lines.\n",
        "the main thing to know from this is that the \\[512\\] is an argument field to GERF_BRA module.\n",
        "The module itself does not need an input but the way that ultralytics reads the yaml file, it assumes\n",
        "each block has an input. So python crashes without this quirk. GERF is dynamic so it changes per input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b27afcb0-32e0-456f-91d7-7e432f025a10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b27afcb0-32e0-456f-91d7-7e432f025a10",
        "outputId": "8ebfb4f9-8fe3-4960-d390-da98b6191025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='n'.\n",
            "Training on GPU\n",
            "Ultralytics 8.3.235 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco-pose.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.1, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=custom/yolo11-gerfpose.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_gerfpose_gpu, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=True, pretrained=True, profile=False, project=runs/pose, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/pose/yolo11n_gerfpose_gpu, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='n'.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1      4224  ultralytics.nn.modules.conv.Conv             [64, 64, 1, 1]                \n",
            " 18                  -1  1     19075  ultralytics.nn.modules.gerf_bra.GERF_BRA_Simple[64, 64, 1]                   \n",
            " 19                  -1  1      4224  ultralytics.nn.modules.conv.Conv             [64, 64, 1, 1]                \n",
            " 20                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 21            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 23                  -1  1     16640  ultralytics.nn.modules.conv.Conv             [128, 128, 1, 1]              \n",
            " 24                  -1  1     64771  ultralytics.nn.modules.gerf_bra.GERF_BRA_Simple[128, 128, 1]                 \n",
            " 25                  -1  1     16640  ultralytics.nn.modules.conv.Conv             [128, 128, 1, 1]              \n",
            " 26                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 27            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 28                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 29        [19, 25, 28]  1    715294  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n",
            "YOLO11-gerfpose summary: 228 layers, 3,000,036 parameters, 3,000,020 gradients\n",
            "\n",
            "Freezing layer 'model.29.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3010.2¬±1001.4 MB/s, size: 182.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco-pose/labels/train2017.cache... 5660 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5660/5660 79.4Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1659.3¬±234.5 MB/s, size: 140.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco-pose/labels/val2017.cache... 2346 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2346/2346 15.8Mit/s 0.0s\n",
            "Plotting labels to /content/runs/pose/yolo11n_gerfpose_gpu/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 91 weight(decay=0.0), 117 weight(decay=0.0005), 116 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/pose/yolo11n_gerfpose_gpu\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      2.72G      3.204     0.8156     0.6691      3.413      3.633         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 2.5it/s 2:22\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 1.1s/it 1:20\n",
            "                   all       2346       6352     0.0628      0.134     0.0294    0.00764    0.00189    0.00236   0.000156   6.81e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      3.78G       2.49     0.7636     0.6055       2.79      2.735         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.1it/s 1:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 21.4s\n",
            "                   all       2346       6352      0.144      0.256     0.0874     0.0291     0.0087    0.00913   0.000458   0.000101\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      3.78G      2.169     0.7374     0.5777      2.485      2.402         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 21.1s\n",
            "                   all       2346       6352      0.218      0.274      0.146     0.0548     0.0271     0.0151    0.00161    0.00031\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20      3.79G      2.005      0.721      0.559      2.309      2.223         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 21.3s\n",
            "                   all       2346       6352      0.307      0.343      0.275       0.11     0.0547     0.0282    0.00653   0.000869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      3.79G      1.894       0.71     0.5438      2.184       2.11         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 20.1s\n",
            "                   all       2346       6352      0.429       0.39      0.367      0.162     0.0553     0.0376    0.00729    0.00117\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      3.79G      1.823     0.6935     0.5259      2.085      2.032         83        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 20.0s\n",
            "                   all       2346       6352      0.498        0.4      0.422      0.199     0.0814     0.0479     0.0135     0.0025\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20      3.79G      1.753     0.6823     0.5143      2.001       1.97         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 21.1s\n",
            "                   all       2346       6352      0.566      0.456      0.479      0.231      0.107     0.0606     0.0171    0.00267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20      3.79G      1.703     0.6723     0.5038      1.936      1.924         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 20.9s\n",
            "                   all       2346       6352      0.536      0.451       0.48      0.237      0.131     0.0705     0.0287    0.00591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20      3.79G       1.67     0.6629     0.4982      1.873      1.889         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.8s\n",
            "                   all       2346       6352      0.602      0.495      0.543      0.272      0.157     0.0928     0.0407     0.0065\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20      3.79G      1.633     0.6527     0.4851      1.817      1.854         64        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 21.0s\n",
            "                   all       2346       6352      0.651      0.498      0.567      0.294      0.173      0.108     0.0451    0.00766\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20      3.79G      1.597     0.6269      0.489      1.764      1.849         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.2it/s 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.8s\n",
            "                   all       2346       6352      0.638      0.491      0.563      0.296      0.174        0.1     0.0446     0.0072\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20      3.79G      1.565     0.6172     0.4801      1.698      1.824         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.7s\n",
            "                   all       2346       6352      0.648      0.523      0.595      0.322      0.179      0.112     0.0497     0.0081\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20      3.79G      1.527     0.6104     0.4731      1.669      1.795         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 21.0s\n",
            "                   all       2346       6352      0.663       0.52      0.595       0.33      0.231      0.131     0.0708     0.0138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      3.79G      1.505     0.6019     0.4704       1.61       1.76         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 20.9s\n",
            "                   all       2346       6352      0.651      0.533      0.605      0.335      0.225      0.143     0.0684     0.0129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20      3.79G       1.47     0.5972     0.4675      1.574      1.737         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.7s\n",
            "                   all       2346       6352       0.68      0.541      0.625      0.358      0.245      0.158     0.0839     0.0167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      3.79G      1.453     0.5924     0.4621       1.55      1.722         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 19.8s\n",
            "                   all       2346       6352       0.69      0.554      0.645      0.373       0.28      0.161     0.0951     0.0192\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      3.79G       1.43     0.5856     0.4588      1.507      1.701         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 20.2s\n",
            "                   all       2346       6352      0.677      0.563      0.649      0.379      0.242      0.166     0.0852     0.0161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      3.79G      1.408     0.5819     0.4554       1.48      1.684         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.5s\n",
            "                   all       2346       6352      0.704      0.571      0.666      0.394      0.284      0.174      0.102     0.0203\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20      3.79G      1.393     0.5805     0.4544      1.461      1.666         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 20.9s\n",
            "                   all       2346       6352      0.718      0.571      0.668        0.4        0.3      0.181      0.108     0.0238\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      3.79G      1.376     0.5742     0.4506      1.431      1.648         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.5it/s 21.0s\n",
            "                   all       2346       6352      0.713      0.586      0.681      0.408      0.301      0.186      0.108     0.0232\n",
            "\n",
            "20 epochs completed in 0.753 hours.\n",
            "Optimizer stripped from /content/runs/pose/yolo11n_gerfpose_gpu/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from /content/runs/pose/yolo11n_gerfpose_gpu/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating /content/runs/pose/yolo11n_gerfpose_gpu/weights/best.pt...\n",
            "Ultralytics 8.3.235 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11-gerfpose summary (fused): 137 layers, 2,991,658 parameters, 0 gradients\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 2.7it/s 27.8s\n",
            "                   all       2346       6352      0.713      0.586      0.681      0.408      0.301      0.185      0.108     0.0232\n",
            "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Saving /content/runs/pose/yolo11n_gerfpose_gpu/predictions.json...\n",
            "\n",
            "Evaluating faster-coco-eval mAP using /content/runs/pose/yolo11n_gerfpose_gpu/predictions.json and /content/datasets/coco-pose/annotations/person_keypoints_val2017.json...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['faster-coco-eval>=1.6.7'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 2 packages in 241ms\n",
            "Prepared 1 package in 46ms\n",
            "Installed 1 package in 20ms\n",
            " + faster-coco-eval==1.7.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 1.2s\n",
            "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished...\n",
            "DONE (t=1.29s).\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.496\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.308\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.074\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.501\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.147\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.469\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.716\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.522\n",
            "Evaluate annotation type *keypoints*\n",
            "COCOeval_opt.evaluate() finished...\n",
            "DONE (t=6.19s).\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.024\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.112\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.004\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.033\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.074\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.264\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.022\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.091\n",
            "Results saved to \u001b[1m/content/runs/pose/yolo11n_gerfpose_gpu\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python mainGERF.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2f092adc-c45c-41b2-93e6-956493f404f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f092adc-c45c-41b2-93e6-956493f404f5",
        "outputId": "72bf2116-bdf9-4fb6-cd15-e606cac167db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running GERF\n",
            "Found 5000 total images in datasets/coco-pose/images/val2017\n",
            "Running inference on first 50 images\n",
            "Processing [1/50]: 000000000139.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000139.jpg: 448x640 (no detections), 60.3ms\n",
            "Speed: 2.5ms preprocess, 60.3ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [2/50]: 000000000285.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000285.jpg: 640x608 2 persons, 61.3ms\n",
            "Speed: 1.8ms preprocess, 61.3ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 608)\n",
            "Processing [3/50]: 000000000632.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000632.jpg: 512x640 1 person, 57.2ms\n",
            "Speed: 1.6ms preprocess, 57.2ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Processing [4/50]: 000000000724.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000724.jpg: 640x480 (no detections), 70.2ms\n",
            "Speed: 2.0ms preprocess, 70.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [5/50]: 000000000776.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000776.jpg: 640x448 (no detections), 57.3ms\n",
            "Speed: 1.4ms preprocess, 57.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [6/50]: 000000000785.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000785.jpg: 448x640 1 person, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [7/50]: 000000000802.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000802.jpg: 640x448 (no detections), 12.1ms\n",
            "Speed: 0.9ms preprocess, 12.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [8/50]: 000000000872.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000872.jpg: 640x640 2 persons, 10.9ms\n",
            "Speed: 2.4ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Processing [9/50]: 000000000885.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000885.jpg: 448x640 3 persons, 10.1ms\n",
            "Speed: 1.0ms preprocess, 10.1ms inference, 2.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [10/50]: 000000001000.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001000.jpg: 480x640 9 persons, 63.4ms\n",
            "Speed: 1.4ms preprocess, 63.4ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [11/50]: 000000001268.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001268.jpg: 448x640 3 persons, 12.5ms\n",
            "Speed: 1.1ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [12/50]: 000000001296.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001296.jpg: 640x448 2 persons, 10.3ms\n",
            "Speed: 1.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [13/50]: 000000001353.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001353.jpg: 640x480 1 person, 14.7ms\n",
            "Speed: 1.8ms preprocess, 14.7ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [14/50]: 000000001425.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001425.jpg: 512x640 (no detections), 10.8ms\n",
            "Speed: 1.6ms preprocess, 10.8ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Processing [15/50]: 000000001490.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001490.jpg: 320x640 1 person, 58.4ms\n",
            "Speed: 0.7ms preprocess, 58.4ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Processing [16/50]: 000000001503.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001503.jpg: 480x640 (no detections), 10.1ms\n",
            "Speed: 1.6ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [17/50]: 000000001532.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001532.jpg: 480x640 (no detections), 9.4ms\n",
            "Speed: 1.0ms preprocess, 9.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [18/50]: 000000001584.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001584.jpg: 640x640 (no detections), 10.9ms\n",
            "Speed: 2.7ms preprocess, 10.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Processing [19/50]: 000000001675.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001675.jpg: 480x640 (no detections), 9.9ms\n",
            "Speed: 1.0ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [20/50]: 000000001761.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001761.jpg: 640x448 (no detections), 10.0ms\n",
            "Speed: 1.0ms preprocess, 10.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [21/50]: 000000001818.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001818.jpg: 448x640 (no detections), 10.0ms\n",
            "Speed: 1.0ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [22/50]: 000000001993.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001993.jpg: 448x640 1 person, 9.7ms\n",
            "Speed: 1.0ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [23/50]: 000000002006.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002006.jpg: 480x640 1 person, 9.9ms\n",
            "Speed: 1.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [24/50]: 000000002149.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002149.jpg: 448x640 (no detections), 9.9ms\n",
            "Speed: 1.2ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [25/50]: 000000002153.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002153.jpg: 480x640 2 persons, 10.3ms\n",
            "Speed: 1.0ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [26/50]: 000000002157.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002157.jpg: 448x640 (no detections), 9.9ms\n",
            "Speed: 1.0ms preprocess, 9.9ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [27/50]: 000000002261.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002261.jpg: 448x640 1 person, 9.7ms\n",
            "Speed: 0.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [28/50]: 000000002299.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002299.jpg: 416x640 14 persons, 63.5ms\n",
            "Speed: 1.4ms preprocess, 63.5ms inference, 6.1ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Processing [29/50]: 000000002431.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002431.jpg: 640x480 1 person, 10.2ms\n",
            "Speed: 1.3ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [30/50]: 000000002473.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002473.jpg: 448x640 1 person, 10.5ms\n",
            "Speed: 1.0ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [31/50]: 000000002532.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002532.jpg: 640x480 1 person, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [32/50]: 000000002587.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002587.jpg: 480x640 (no detections), 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [33/50]: 000000002592.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002592.jpg: 384x640 1 person, 57.4ms\n",
            "Speed: 0.9ms preprocess, 57.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing [34/50]: 000000002685.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002685.jpg: 576x640 2 persons, 58.9ms\n",
            "Speed: 2.2ms preprocess, 58.9ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "Processing [35/50]: 000000002923.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002923.jpg: 480x640 (no detections), 10.3ms\n",
            "Speed: 1.7ms preprocess, 10.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [36/50]: 000000003156.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003156.jpg: 640x448 1 person, 10.0ms\n",
            "Speed: 1.0ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [37/50]: 000000003255.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003255.jpg: 384x640 (no detections), 10.4ms\n",
            "Speed: 0.9ms preprocess, 10.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing [38/50]: 000000003501.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003501.jpg: 640x640 1 person, 10.9ms\n",
            "Speed: 3.1ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Processing [39/50]: 000000003553.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003553.jpg: 448x640 (no detections), 10.1ms\n",
            "Speed: 1.0ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [40/50]: 000000003661.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003661.jpg: 384x640 (no detections), 10.1ms\n",
            "Speed: 1.1ms preprocess, 10.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing [41/50]: 000000003845.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003845.jpg: 480x640 (no detections), 11.0ms\n",
            "Speed: 2.5ms preprocess, 11.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [42/50]: 000000003934.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003934.jpg: 640x480 6 persons, 13.5ms\n",
            "Speed: 1.7ms preprocess, 13.5ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [43/50]: 000000004134.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004134.jpg: 448x640 8 persons, 11.7ms\n",
            "Speed: 1.1ms preprocess, 11.7ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [44/50]: 000000004395.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004395.jpg: 640x448 1 person, 10.1ms\n",
            "Speed: 1.1ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [45/50]: 000000004495.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004495.jpg: 480x640 (no detections), 13.0ms\n",
            "Speed: 1.6ms preprocess, 13.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [46/50]: 000000004765.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004765.jpg: 640x640 1 person, 16.7ms\n",
            "Speed: 3.6ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Processing [47/50]: 000000004795.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004795.jpg: 480x640 (no detections), 10.1ms\n",
            "Speed: 1.0ms preprocess, 10.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [48/50]: 000000005001.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000005001.jpg: 480x640 10 persons, 10.1ms\n",
            "Speed: 1.0ms preprocess, 10.1ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [49/50]: 000000005037.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000005037.jpg: 448x640 (no detections), 10.0ms\n",
            "Speed: 1.0ms preprocess, 10.0ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [50/50]: 000000005060.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000005060.jpg: 640x480 1 person, 10.6ms\n",
            "Speed: 1.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Inference complete on 50 images. Results saved.\n"
          ]
        }
      ],
      "source": [
        "!python inferenceGERF.py\n",
        "!mkdir -p results\n",
        "!mkdir -p results/gerf\n",
        "!mv *.jpg results/gerf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "665a8ec5-bab2-4e3a-bc55-47814bc164c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "665a8ec5-bab2-4e3a-bc55-47814bc164c3",
        "outputId": "4d51f046-06a1-4620-faa7-191b19372bab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='n'.\n",
            "Ultralytics 8.3.235 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco-pose.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=0.1, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=custom/yolo11-pose.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_pose_gpu, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=50, perspective=0.0, plots=True, pose=True, pretrained=True, profile=False, project=runs/pose, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/pose/yolo11n_pose_gpu, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "WARNING ‚ö†Ô∏è no model scale passed. Assuming scale='n'.\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    715294  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n",
            "YOLO11-pose summary: 196 layers, 2,874,462 parameters, 2,874,446 gradients\n",
            "\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 394.4¬±699.6 MB/s, size: 182.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco-pose/labels/train2017... 5660 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5660/5660 364.4it/s 15.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco-pose/labels/train2017.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 224.8¬±422.7 MB/s, size: 140.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco-pose/labels/val2017.cache... 2346 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2346/2346 16.8Mit/s 0.0s\n",
            "Plotting labels to /content/runs/pose/yolo11n_pose_gpu/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/pose/yolo11n_pose_gpu\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      2.44G      3.162     0.8135     0.6712      3.368      3.611         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 2.7it/s 2:14\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 1.1it/s 1:05\n",
            "                   all       2346       6352     0.0612      0.167     0.0324    0.00846    0.00154    0.00331   0.000144   4.53e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      3.49G      2.439     0.7609     0.6053      2.753      2.696         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.4it/s 21.9s\n",
            "                   all       2346       6352      0.205      0.263      0.156     0.0513     0.0193     0.0146    0.00137   0.000232\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      3.51G       2.13     0.7363     0.5768      2.438      2.367         65        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.4it/s 1:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.3s\n",
            "                   all       2346       6352      0.301      0.282      0.215     0.0742     0.0234     0.0159    0.00253   0.000617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20      3.51G      1.996     0.7199     0.5544      2.273      2.217         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.3it/s 1:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.4it/s 21.9s\n",
            "                   all       2346       6352      0.396      0.368      0.315      0.126     0.0884     0.0296    0.00776    0.00119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      3.51G      1.882     0.7065     0.5392      2.161      2.113         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.4it/s 1:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.9it/s 19.2s\n",
            "                   all       2346       6352      0.458      0.378      0.371      0.161      0.074     0.0417    0.00993    0.00161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      3.51G       1.81     0.6899     0.5204      2.059      2.039         83        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.4it/s 1:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 20.3s\n",
            "                   all       2346       6352      0.531      0.391      0.437      0.206     0.0765     0.0527     0.0172    0.00266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20      3.51G      1.752     0.6795     0.5095       1.99      1.976         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.4it/s 1:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.5s\n",
            "                   all       2346       6352      0.552      0.466       0.49      0.231      0.103     0.0786     0.0226    0.00387\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20      3.51G      1.704     0.6701     0.4994      1.929      1.928         70        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.4it/s 1:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.3s\n",
            "                   all       2346       6352      0.593      0.457      0.517      0.255      0.103     0.0706     0.0248    0.00483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20      3.51G      1.671     0.6603     0.4932      1.856      1.893         57        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.4it/s 1:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.8it/s 19.5s\n",
            "                   all       2346       6352      0.609      0.496      0.552      0.278      0.182        0.1     0.0422    0.00703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20      3.51G      1.632     0.6526      0.484       1.81      1.858         64        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.4it/s 1:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 20.0s\n",
            "                   all       2346       6352      0.619      0.514      0.575      0.292      0.156     0.0929     0.0369     0.0057\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20      3.51G      1.617     0.6245     0.4891      1.756      1.863         32        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.4it/s 1:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.6it/s 20.3s\n",
            "                   all       2346       6352      0.644      0.527      0.599      0.313      0.172      0.108     0.0456    0.00765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20      3.53G       1.58     0.6189     0.4818      1.693      1.831         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:40\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.8it/s 19.6s\n",
            "                   all       2346       6352      0.669      0.512      0.599      0.328      0.222      0.123     0.0633     0.0109\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20      3.53G      1.538     0.6115      0.474       1.66      1.797         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.9it/s 19.2s\n",
            "                   all       2346       6352      0.663      0.549      0.625      0.341      0.229      0.145     0.0713      0.014\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      3.53G      1.517     0.6025     0.4705      1.604      1.769         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 20.1s\n",
            "                   all       2346       6352      0.661      0.561      0.634      0.347      0.211       0.14     0.0623     0.0114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20      3.53G      1.495     0.5972     0.4663      1.573      1.755         22        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.8it/s 19.6s\n",
            "                   all       2346       6352      0.696      0.556       0.65      0.366      0.275      0.154     0.0847      0.016\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      3.53G      1.476     0.5935     0.4631       1.55      1.743         51        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.8it/s 19.2s\n",
            "                   all       2346       6352      0.676      0.572      0.654      0.376      0.283      0.162     0.0913     0.0182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      3.53G      1.443     0.5863     0.4597        1.5      1.714         23        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 20.1s\n",
            "                   all       2346       6352      0.715      0.563      0.664      0.384      0.255      0.166      0.089     0.0167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      3.53G      1.423     0.5828     0.4573      1.474      1.696         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 19.8s\n",
            "                   all       2346       6352      0.707      0.572      0.671       0.39      0.294      0.176     0.0995     0.0204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20      3.53G      1.412     0.5805     0.4557      1.459      1.684         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.8it/s 19.4s\n",
            "                   all       2346       6352       0.72      0.579      0.677        0.4      0.311      0.183      0.108      0.023\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      3.53G       1.39     0.5751     0.4527      1.426      1.663         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 354/354 3.5it/s 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 3.7it/s 20.1s\n",
            "                   all       2346       6352      0.721      0.588      0.685      0.406      0.329      0.183      0.113     0.0237\n",
            "\n",
            "20 epochs completed in 0.713 hours.\n",
            "Optimizer stripped from /content/runs/pose/yolo11n_pose_gpu/weights/last.pt, 6.0MB\n",
            "Optimizer stripped from /content/runs/pose/yolo11n_pose_gpu/weights/best.pt, 6.0MB\n",
            "\n",
            "Validating /content/runs/pose/yolo11n_pose_gpu/weights/best.pt...\n",
            "Ultralytics 8.3.235 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11-pose summary (fused): 109 layers, 2,866,468 parameters, 0 gradients\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 74/74 2.7it/s 27.1s\n",
            "                   all       2346       6352      0.719      0.588      0.685      0.406      0.329      0.182      0.113     0.0237\n",
            "Speed: 0.2ms preprocess, 1.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Saving /content/runs/pose/yolo11n_pose_gpu/predictions.json...\n",
            "\n",
            "Evaluating faster-coco-eval mAP using /content/runs/pose/yolo11n_pose_gpu/predictions.json and /content/datasets/coco-pose/annotations/person_keypoints_val2017.json...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['faster-coco-eval>=1.6.7'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 2 packages in 359ms\n",
            "Prepared 1 package in 24ms\n",
            "Installed 1 package in 17ms\n",
            " + faster-coco-eval==1.7.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 1.4s\n",
            "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Evaluate annotation type *bbox*\n",
            "COCOeval_opt.evaluate() finished...\n",
            "DONE (t=1.31s).\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.294\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.500\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.378\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.146\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.466\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.576\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.717\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.520\n",
            "Evaluate annotation type *keypoints*\n",
            "COCOeval_opt.evaluate() finished...\n",
            "DONE (t=5.77s).\n",
            "Accumulating evaluation results...\n",
            "COCOeval_opt.accumulate() finished...\n",
            "DONE (t=0.00s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.026\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.110\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.003\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.026\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.072\n",
            " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.255\n",
            " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.019\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.058\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.091\n",
            "Results saved to \u001b[1m/content/runs/pose/yolo11n_pose_gpu\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python mainYolo11.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "STJ0B9tao9-_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STJ0B9tao9-_",
        "outputId": "6b3c8585-0945-4ba7-f38f-64e7d4ae9607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Normal Yolo\n",
            "Found 5000 total images in datasets/coco-pose/images/val2017\n",
            "Running inference on first 50 images\n",
            "Processing [1/50]: 000000000139.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000139.jpg: 448x640 (no detections), 63.7ms\n",
            "Speed: 2.4ms preprocess, 63.7ms inference, 0.8ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [2/50]: 000000000285.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000285.jpg: 640x608 1 person, 55.5ms\n",
            "Speed: 1.8ms preprocess, 55.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 608)\n",
            "Processing [3/50]: 000000000632.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000632.jpg: 512x640 (no detections), 69.6ms\n",
            "Speed: 1.6ms preprocess, 69.6ms inference, 0.6ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Processing [4/50]: 000000000724.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000724.jpg: 640x480 (no detections), 58.6ms\n",
            "Speed: 2.0ms preprocess, 58.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [5/50]: 000000000776.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000776.jpg: 640x448 (no detections), 57.2ms\n",
            "Speed: 1.4ms preprocess, 57.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [6/50]: 000000000785.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000785.jpg: 448x640 1 person, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [7/50]: 000000000802.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000802.jpg: 640x448 (no detections), 8.3ms\n",
            "Speed: 1.0ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [8/50]: 000000000872.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000872.jpg: 640x640 1 person, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Processing [9/50]: 000000000885.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000000885.jpg: 448x640 4 persons, 8.9ms\n",
            "Speed: 1.0ms preprocess, 8.9ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [10/50]: 000000001000.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001000.jpg: 480x640 8 persons, 56.3ms\n",
            "Speed: 1.3ms preprocess, 56.3ms inference, 4.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [11/50]: 000000001268.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001268.jpg: 448x640 2 persons, 9.1ms\n",
            "Speed: 1.1ms preprocess, 9.1ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [12/50]: 000000001296.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001296.jpg: 640x448 1 person, 8.7ms\n",
            "Speed: 1.4ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [13/50]: 000000001353.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001353.jpg: 640x480 1 person, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [14/50]: 000000001425.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001425.jpg: 512x640 (no detections), 9.3ms\n",
            "Speed: 1.4ms preprocess, 9.3ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Processing [15/50]: 000000001490.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001490.jpg: 320x640 1 person, 56.1ms\n",
            "Speed: 0.8ms preprocess, 56.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Processing [16/50]: 000000001503.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001503.jpg: 480x640 2 persons, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [17/50]: 000000001532.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001532.jpg: 480x640 (no detections), 10.2ms\n",
            "Speed: 1.6ms preprocess, 10.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [18/50]: 000000001584.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001584.jpg: 640x640 (no detections), 9.7ms\n",
            "Speed: 2.9ms preprocess, 9.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Processing [19/50]: 000000001675.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001675.jpg: 480x640 (no detections), 8.7ms\n",
            "Speed: 1.1ms preprocess, 8.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [20/50]: 000000001761.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001761.jpg: 640x448 (no detections), 8.5ms\n",
            "Speed: 1.3ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [21/50]: 000000001818.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001818.jpg: 448x640 (no detections), 8.4ms\n",
            "Speed: 0.9ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [22/50]: 000000001993.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000001993.jpg: 448x640 (no detections), 7.9ms\n",
            "Speed: 0.9ms preprocess, 7.9ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [23/50]: 000000002006.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002006.jpg: 480x640 1 person, 8.2ms\n",
            "Speed: 1.0ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [24/50]: 000000002149.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002149.jpg: 448x640 (no detections), 9.2ms\n",
            "Speed: 1.2ms preprocess, 9.2ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [25/50]: 000000002153.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002153.jpg: 480x640 4 persons, 8.2ms\n",
            "Speed: 1.0ms preprocess, 8.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [26/50]: 000000002157.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002157.jpg: 448x640 (no detections), 8.1ms\n",
            "Speed: 1.0ms preprocess, 8.1ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [27/50]: 000000002261.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002261.jpg: 448x640 1 person, 7.6ms\n",
            "Speed: 0.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [28/50]: 000000002299.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002299.jpg: 416x640 19 persons, 54.8ms\n",
            "Speed: 1.4ms preprocess, 54.8ms inference, 7.7ms postprocess per image at shape (1, 3, 416, 640)\n",
            "Processing [29/50]: 000000002431.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002431.jpg: 640x480 4 persons, 8.5ms\n",
            "Speed: 1.6ms preprocess, 8.5ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [30/50]: 000000002473.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002473.jpg: 448x640 1 person, 15.3ms\n",
            "Speed: 1.3ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [31/50]: 000000002532.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002532.jpg: 640x480 2 persons, 9.3ms\n",
            "Speed: 1.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [32/50]: 000000002587.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002587.jpg: 480x640 (no detections), 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [33/50]: 000000002592.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002592.jpg: 384x640 2 persons, 55.1ms\n",
            "Speed: 0.8ms preprocess, 55.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing [34/50]: 000000002685.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002685.jpg: 576x640 3 persons, 57.6ms\n",
            "Speed: 1.9ms preprocess, 57.6ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n",
            "Processing [35/50]: 000000002923.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000002923.jpg: 480x640 (no detections), 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [36/50]: 000000003156.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003156.jpg: 640x448 2 persons, 8.3ms\n",
            "Speed: 0.9ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [37/50]: 000000003255.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003255.jpg: 384x640 (no detections), 8.3ms\n",
            "Speed: 0.9ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing [38/50]: 000000003501.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003501.jpg: 640x640 (no detections), 9.0ms\n",
            "Speed: 3.4ms preprocess, 9.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Processing [39/50]: 000000003553.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003553.jpg: 448x640 1 person, 8.5ms\n",
            "Speed: 1.0ms preprocess, 8.5ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [40/50]: 000000003661.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003661.jpg: 384x640 (no detections), 10.6ms\n",
            "Speed: 1.1ms preprocess, 10.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processing [41/50]: 000000003845.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003845.jpg: 480x640 1 person, 8.2ms\n",
            "Speed: 1.9ms preprocess, 8.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [42/50]: 000000003934.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000003934.jpg: 640x480 6 persons, 8.3ms\n",
            "Speed: 1.6ms preprocess, 8.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Processing [43/50]: 000000004134.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004134.jpg: 448x640 8 persons, 8.7ms\n",
            "Speed: 0.9ms preprocess, 8.7ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [44/50]: 000000004395.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004395.jpg: 640x448 1 person, 8.3ms\n",
            "Speed: 1.0ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
            "Processing [45/50]: 000000004495.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004495.jpg: 480x640 (no detections), 8.5ms\n",
            "Speed: 1.6ms preprocess, 8.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [46/50]: 000000004765.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004765.jpg: 640x640 1 person, 9.1ms\n",
            "Speed: 2.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Processing [47/50]: 000000004795.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000004795.jpg: 480x640 (no detections), 8.3ms\n",
            "Speed: 1.0ms preprocess, 8.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [48/50]: 000000005001.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000005001.jpg: 480x640 7 persons, 8.3ms\n",
            "Speed: 1.1ms preprocess, 8.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Processing [49/50]: 000000005037.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000005037.jpg: 448x640 2 persons, 8.3ms\n",
            "Speed: 1.0ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Processing [50/50]: 000000005060.jpg\n",
            "\n",
            "image 1/1 /content/datasets/coco-pose/images/val2017/000000005060.jpg: 640x480 1 person, 10.9ms\n",
            "Speed: 1.1ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Inference complete on 50 images. Results saved.\n"
          ]
        }
      ],
      "source": [
        "!python inferenceYOLO.py\n",
        "!mkdir -p results\n",
        "!mkdir -p results/yolo\n",
        "!mv *.jpg results/yolo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HFbE0lxQo-vS",
      "metadata": {
        "id": "HFbE0lxQo-vS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}